%%	SECCION documentclass																									 %%	
%%---------------------------------------------------------------------------%%
\documentclass[a4paper]{report}
%%---------------------------------------------------------------------------%%
%%	SECCION usepackage																											 %%	
%%---------------------------------------------------------------------------%%
\usepackage{amsmath, amsthm}
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{caratula}
\usepackage{hyperref} %para que haya hiperv涌쪑culos
\usepackage{graphicx} % Para el logo magico!
\usepackage{alltt} % que es este paquete???

\usepackage[spanish]{babel} 
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
%\usepackage[latin1]{inputenc}

\oddsidemargin 0cm
\headsep -1.4cm
\textwidth=16.5cm
\textheight=23cm
%\makeindex



%%---------------------------------------------------------------------------%%
%%	SECCION document	                                                       %%	
%%---------------------------------------------------------------------------%%
\begin{document}
	\setcounter{page}{0} %para que numere a la caratula como p涌쪊ina 0 y a las demas a partir de 1

%%---- Caratula -------------------------------------------------------------%%
\title{Trabajo Pr치ctico}
\author{Matias, Rodrigo y Martin\thanks{This is for making an acknowledgement.}
\\Universidad de Buenos Aires, Argentina}
\date{14 April, 2009}

\materia{Teoria de lenguajes}
\titulo{Trabajo Pr치ctico}
\subtitulo{Generador de analizadores sint치cticos}
\fecha{18 de junio, 2009}

\integrante{Rodrigo Campos}{561/06}{rodrigo@sdfg.com.ar}
\integrante{Mart칤n Fernandez}{539/06/}{bondi007@gmail.com}
\integrante{Mat칤as P칠rez}{002/05}{elmaildematiaz@gmail.com}
%\resumen{}

\maketitle

%\tableofcontents

\newpage

\clearpage

\section*{An\'alisis del lenguaje de especificaci\'on de gram\'aticas}
Tal como planteaba el enunciado de este trabajo pr\'actico, el conjunto de producciones pertenecientes a la gram\'atica que definir\'a el lenguaje para el cual finalmente se generar\'a el 
analizador sint\'actico pertinente, se encontraba expresado en un lenguaje que especifica producciones de gram\'atica. Para dicho lenguaje se conoc\'ia, mediante el enunciado, su conjunto de producciones. As\'i, por ejemplo la cadena \textbf{ A:aB | C ; } escrita en el lenguaje mencionado, representaba la producci\'on A -> aB | C, para cualquier gram\'atica que la incluyera entre sus producciones.
Dada esta situaci\'on, se tornaba fundamental comprender qu\'e producci\'on estaba representando efectivamente cada cadena escrita en el mencionado lenguaje de especificaci\'on. Adem\'as de esto, era indispensable poder verificar si dada una cadena escrita con los s\'imbolos que define el lenguaje de especificaci\'on en cuesti\'on, la misma pertenece o no al lenguaje.
Ante estas necesidades, decidimos utilizar un analizador sint\'actico llamado \textbf{pyparsing}, para el lenguaje de programaci\'on \textbf{python}. Este analizador nos ofrec\'ia las funcionalidades requeridas y por ende nos permit\'ia verificar si dada una cadena, la misma pertenec\'ia a alg\'un lenguaje para el cual se le especificaran al mismo las reglas de construcci\'on de las producciones asociadas a su gram\'atica.
Sin embargo, en el momento de intentar utilizar pyparsing para analizar el lenguaje de especificaciones nos encontramos con que el conjunto de producciones dado en el enunciado que defin\'ia la gram\'atica de dicho lenguaje, conformaba una gram\'atica ambig\"'ua. Por ende, antes de proseguir con el desarrollo, nos encontramos ante la necesidad de desambig\"'uar la gram\'atica definida en el enunciado de este trabajo pr\'actico. Con lo cual pasamos de tener inicialmente el siguiente conjunto de producciones:

\begin{itemize}
	\item G  -> P G | P
	\item P  -> m ':'  PD ';'
	\item PD -> n | t | $\lambda$ |PD | PD PD | PD '*' | PD '+' | PD '?'  | '(' PD ')'
\end{itemize}

(en donde \textbf{t} representa a un caracter en min\'uscula, que a su vez representa un s\'imbolo terminal en la gram\'atica que se intenta definir. El comportamiento de \textbf{n} es an\'alogo, pero respecto a los no terminales de la gram\'atica a definir, para lo cual n es un caracter en may\'uscula).

a tener finalmente el conjunto de producciones desambig\"'uado que se presenta a continuaci\'on

\begin{itemize}
	\item G 		-> Prod (OtrasProd)*
	\item Prod 	-> n ':' ProdDer ';'
	
\end{itemize}

Una vez desambig\"'uada la gram\'atica, podiamos utilizar finalmente pyparsing para analizarla. Ahora, nos resultaba bastante sencillo determinar si una cadena representaba o no una producci\'on v\'alida construida en base a la gram\'atica del lenguaje de especificacion de gram\'aticas. Sin embargo, todav\'ia nos quedaba la ardua tarea de generar el grafo con el cual trabajar\'ian los algoritmos de c\'alculo de \textbf{anulables}, \textbf{primeros}, \textbf{siguientes}, y \textbf{s\'imbolos directrices}, que son explicados posteriormente. En un principio creimos que podr\'iamos realizar ambas tareas ("`parsear"' la gram\'atica inicial y armar el grafo correspondiente a la gram\'atica definida por la gram\'atica inicial) en forma secuencial. Es decir, primero utilizar pyparsing para verificar que cada producci\'n definida estuviera bien construida y perteneciera al lenguaje y luego en base a un algoritmo implementado por nosotros construir el grafo en cuesti\'on. Lamentablemente, el intento result\'o fallido, dado que la implementaci\'on de dicho algoritmo deb\'ia contemplar una gran cantidad de casos particulares, y resultaba ademas de "`endeble"', complicado de explicar y de entender y extremadamente complejo a la hora de realizar tares de test y posterior "`debug"'. Con lo cual, decidimos encarar la soluci\'on de este problema por otro camino. Tomamos la decisi\'on entonces de revisar la documentaci\'on de pyparsing con el objetivo de verificar si el mismo no nos pod\'ia "`dar una mano"' con la construcci\'on del grafo. Finalmente, descubrimos que pyparsing permit\'ia realizar llamados a funciones auxiliares durante el proceso de an\'alisis de una cadena. De esta manera, cada vez que encontrabamos un operador (como ser '*', '+', '?'), un conector (como ser '|', o implicitamente un conector de concatenaci\'on), un s\'imbolo no terminal, o uno terminal pod\'iamos llamar a la funci\'on auxiliar correspondiente a cada uno de ellos que se encargaba de, en cada caso, modificar o seguir construyendo (o ambas simultaneamente) el grafo representativo de la gram\'atica en cuesti\'on.

\subsection*{Breve rese\~{n}a acerca de pyparsing}
Pyparsing es un analizador sint徑tico que, como tal, permite enunciar un conjunto de reglas sobre las cuales se construyen las cadenas v涇idas de un lenguaje. Estas reglas guardan gran similitud con las producciones que usualmente se utilizan para describir el comportamiento de una gram磬ica. Mientras que en el lenguaje natural de gram\'aticas el s\'imbolo \

\section*{Comprobar que la gram\'atica sea ELL(1)}

Para asgurarnos que la gram치tica sea ELL(1), hacemos dos checkeos en dos
momentos distintos.


Antes de hacer cualquier checkeo, reducimos la gram치tica (es
decir, hacemos que todos los no-terminales sean alcanzables y activos). Luego,
por el teorema visto en clase que dice:
\begin{itemize}
\item Para toda gramatica G reducida (osea, una en las cuales todos lo
	no-terminales son alcanzables y activos), si G es independiente de contexto
	y LL(1), entonces G no es recursiva a izquierda.
\end{itemize}


Checkeamos si tiene recursi칩n a izquierda, y si es as칤, concluimos que no es
ELL(1).


Es decir, suponemos que la gram치tica es ELL(1). Sabemos entonces que no
tiene recursi칩n a izquierda. Si al checkear vemos que tiene recursi칩n a
izquierda, entonces llegamos a un absurdo que vino de suponer que era ELL(1). Es
decir que podemos concluir que la gram치tica no es ELL(1).


Para poder aplicar el teorema anterior es necesario ver que la gram치tica es
independiente de contexto. Para ver esto, podemos ver c칩mo se reescribir칤a cada
s칤mbolo que agregan las expresions regulares en producciones de una gram치tica
independiente de contexto y ver entonces que cada gram치tica cuyas producciones
son expresiones regulares se puede transformar en una gram치tica independiente de
contexto que genera el mismo lenguaje.

\begin{itemize}
\item Por cada expresion A -> B | C, se puede transformar en dos producciones: A -> B
y A -> C.
\item Por cada expresion A -> B*, se puede transformar en: A -> BA y A -> $\lambda$
\item Por cada expresion A -> B+, se puede transformar en: A -> BA' y A' -> B y A' -> $\lambda$
\item Por cada expresion A -> B?, se puede transformar en: A -> B y A -> $\lambda$
\end{itemize}


Es f치cil ver que ambas expresiones tienen el mismo lenguaje.


Para transformar una expresi칩n regular cualquiera, lo que se hace es por cada
'B*' que tenga, se puede introducir un nuevo no-terminal A, tal que A -> BA y A
-> $\lambda$, y reemplazar 'B*' en la expresi칩n regular por A. Haciendo lo mismo para el
resto de los s칤mbolos siguiendo las transformaciones explicadas arriba, se puede
ver que cualquier expresi칩n regular se puede transformar en una gram치tica
independiente de contexto equivalente.


Se puede notar tambi칠n, de la forma de transformar las expresiones regulares,
que si la expresi칩n regular ten칤a recursi칩n a izquierda, entonces luego de
transformarlas tambi칠n tendr치n.


Es decir, si A -> B* tiene recursion a izquierda, entonces es A -> A*, y las
producciones generadas seran A -> AA y A -> $\lambda$, es decir que hay recursi칩n a
izquierda. Es f치cil ver que para el resto de los casos sucede lo mismo


El segundo checkeo para ver que sea ELL(1), es el que vimos en clase, que lo
hacemos luego de calcular anulables, primeros, siguientes y los simbolos
directrices. Es decir, checkeamos que para cada '|', los simbolos directrices de
sus hijos sean disjuntos y para cada '+', '*', '?', checkeamos que los primeros
del nodo hijo sea disjunto con los siguientes del nodo y que ningun hijo sea
anulable.


\section*{Reducir la gram치tica}

	Para reducir la gram치tica, primero buscamos cu치les son los nodos 칰tiles
del grafo.


	Para esto primero buscamos los nodos activos, recorremos el grafo partiendo desde el
simbolo distinguido, y por cada nodo, si es un terminal, $\lambda$, '*' o '?', lo
marcamos como activo (pues siempre producen algo, ese terminal o $\lambda$). A cada
no-terminal o '|', lo marcamos como activo si alguno de sus hijos es 칰til. Y al
'.' y '+' los marcamos como activo s칩lo si todos sus hijos son 칰tiles. Esto lo
hacemos hasta que recorramos el grafo entero sin marcar ning칰n nodo nuevo como activo.


	De esta forma tenemos cu치les son los nodos activos del grafo. Luego, lo
que hacemos es sacar todos los links que tenga un nodo a un nodo inactivo,
partiendo desde el s칤mbolo distinguido. Es f치cil ver que esto es correcto, pues:


\begin{itemize}
\item Si el nodo es no-terminal o '|', entonces esos casos, que nunca producir칤an nada,
se pueden ignorar.

\item Si el nodo es un '*' o '+' y sus hijos no son activos,
entonces lo reemplazamos por $\lambda$ y sacamos el link a su hijo, ya que es lo
칰nico que pueden producir 

\item Si, en cambio, es un '.' (representaci\'on utilizada para la operaci\'on de concatenaci\'on) o un '+', el nodo est\'a activo si todos sus hijos tienen la misma condici\'on, por lo que si tienen un hijo 
inactivo ellos tambi칠n lo son, y por tanto,
el padre sacar치 el link hacia ellos. Si no llegamos al no-terminal partiendo
desde el simbolo distinguido, el no-terminal era inalcanzable, por lo que lo podemos ignorar.
\end{itemize}


	Luego de este procedimiento convertimos a los nodos inactivos en inalcanzables, 
ya que los "desligamos" de la componente conexa que contiene al simbolo distinguido. Una vez 
que tenemos esto lo 칰nico que hace falta es quitar los nodos inalcanzables, para esto simplemente 
primero los reconocemos recorriendo la componente conexa y a medida que lo hacemos generamos 
el conjunto de los nodos de la misma, para luego reemplazar al conjunto de nodos del grafo 
por este nuevo conjunto.


	Finalmente, despu칠s de aplicar estos dos procedimientos, el grafo se
corresponde al de una gram치tica reducida (pues todos sus s\'imbolos no-terminales son
activos y alcanzables)


\section*{Checkear la recursi\'on a izquierda}

	Para analizar la recursi\'on a izquierda, usamos una idea muy similar a la que
utilizamos para realizar el c\'alculo de "`primeros"'. Recorremos el grafo de la misma manera, las
diferencias son:


\begin{itemize}

\item Si el nodo actual es un terminal o $\lambda$, lo ignoramos.

\item Si es '|', '*', '?', '+' o un no-terminal, hacemos lo mismo que hace primeros y adem치s, para cada hijo si es un no-terminal que no pertenece a rec\_iz del nodo actual, lo agregamos y macarmos que cambi칩 algo en
esta iteraci칩n.

\item Si es '.', hacemos lo mismo que hace primeros para cada hijo, solo que adem치s tambi칠n si el hijo es un no-terminal lo agregamos a rec\_iz del
nodo actual.

\end{itemize}


	Como consecuencia de esto, al finalizar tendremos un diccionario, el cual dado un nodo nos
dice con qu칠 no-terminales puede comenzar (por esto es que es muy similar a
primeros). Si alg칰n nodo puede comenzar con 칠l mismo, entonces tiene recursi칩n a
izquierda. Si, por el contrario, ninguno de ellos puede comenzar con si mismo, entonces no se tiene
recursi칩n a izquierda presente en la gram\'atica.


\section*{Simbolos directrices}

Para calcular los simbolos directrices, primero calculamos para cada nodo, los
anulables, los primeros y los siguientes.


Luego creamos un diccionario que tenga una entrada por cada nodo del grafo cuyo
valor sea los primeros del mismo, y si dicho nodo es anulable, le agregamos los
siguientes del nodo.


Para todos estos algoritmos utilizamos la misma forma de recorrer el grafo:
recorremos el grafo hasta que en una recorrida entera del grafo no hayamos
agregado nada a lo que estamos calculando (anulables, primeros o siguientes). Si
no cambio nada en una recorrida completa del grafo, es porque entonces ya hemos
calculado lo que quer칤amos calcular.

\subsection*{Anulables}

	En cada paso (o nodo) entonces, lo que hacemos es fijarnos si el nodo
actual est치 en el conjunto de nodos anulables y sino y cumple ciertos
requisitos, lo agregamos y marcamos que cambi칩 algo en esta iteraci칩n.


	Los requisitos dependen del nodo actual, si es un terminal, nunca es
anulable, por lo que no lo agregamos. Si es '*', '?' o '$\lambda$', siempre es anulable
por lo que lo agregamos. Si es un no-terminal o un '|', es anulable si alguno de
sus hijos es anulable. Y si es un '.' o '+', es anulable si todos sus hijos son
anulables.


	Al terminar de recorrer el grafo, tenemos el conjunto de nodos
anulables.

\subsection*{Primeros}

	En cada paso, lo que hacemos es fijarnos cierta relacion entre los primeros
del nodo actual y sus hijos, si no la cumplen los agregamos y marcamos que
cambi칩 algo en esta iteraci칩n.


	Si el nodo actual es un no terminal y el caracter no pertenece a los
primeros del nodo actual, lo agregamos. Si es un $\lambda$, lo ignoramos. Si es un
'|', '*', '?', '+' o un no-terminal, entonces nos fijamos que contenga a los
primeros de todos sus hijos. Si no los contiene, los agregamos y marcamos que
algo cambio en esta iteracion. Y si es '.', nos fijamos si contiene a los
primeros de su primer hijo (el de m치s a la izquierda), si no los contiene lo
agregamos y marcamos que cambi칩 algo. Si el primer hijo es anulable, nos fijamos
que contenga a los primeros del segundo hijo, si no los contiene los agregamos y
marcamos que cambi칩 algo en esta iteraci칩n. Y as칤 con los sucesivos hijos hasta
que no tenga m치s o encontrar uno no anulable.


	Cuando hayamos recorrido el grafo entero sin cambiar nada, entonces
sabemos que todas las condiciones se cumplen, por lo que es f치cil ver que se ha
calculado los primeros de cada nodo correctamente.


\subsection*{Siguientes}

	En cada paso, lo que hacemos es fijarnos cierta relacion entre los
siguientes del nodo actual y sus hijos, si no la cumplen los agregamos y marcamos que
cambi칩 algo en esta iteraci칩n.


	Si el nodo actual es un termian o $\lambda$, lo ignoramos. Si es un '|',
'*', '?', '+' o un no-terminal, entonces nos fijamos que los siguientes de todos
sus hijos incluyan a los siguientes del nodo actual. Si no es as칤, los inclu칤mos
y marcamos que algo cambi칩 en esta iteraci칩n. Si es un '.' nos fijamos que los
siguientes del '.' sean tambien siguientes de su 칰ltimo hijo (el de m치s a la
derecha), si no es as칤 los agregamos y marcamos que cambi칩. Si el 칰ltimo hijo es
anulable, entonces nos fijamos que los siguientes de '.' tambi칠n sean siguientes
del nodo anterior al 칰ltimo y lo agregamos si no los incluye. Y lo mismo con el
anterior y as칤 sucesivamente hasta llegar a uno que no es anulable. Tambi칠n,
para cada dos hijos 'x' e 'y', consecutivos ('x' m치s a la izquierda que 'y'),
nos fijamos que los siguientes de 'x' contengan a los primeros de 'y', si no es
as칤 los agregamos. Y si 'y' es anulable, nos fijamos que los siguientes de 'x'
contenga a los a los siguientes de 'y'.


	Cuando hayamos recorrido el grafo entero sin cambiar nada, entonces
sabemos que todas las condiciones se cumplen, por lo que es f치cil ver que se ha
calculado los siguientes de cada nodo correctamente.


\section*{Generaci칩n de c칩digo}


Para generar el c칩digo que parsee las cadenas del lenguaje de la gram치tica que se 
obtiene como entrada cumpliendo con los requisitos pedidos se decidi칩 elegir el lenguaje C++. Para hacerlo se procede de la siguiente forma.


Por un lado se tienen dos archivos \emph{ParserEll1.cpp} y \emph{Utilitario.cpp} estos contienen un main general y estandar
que lo 칰nico que hace es leer la cadena de entrada, setear un par de variables y llamar a la funcion "parsear()" 
que ser치 generada en el archivo \emph{codigoParser.cpp} que es el que se generar치. El archivo \emph{Utilitario.cpp} 
es el que contiene la l칩gica del match, que se encarga de ver si la letra pasada para realizar el match es la misma del \emph{TC} 
(Token Corriente), en caso de serlo aumenta el \emph{TC} y en caso contrario tira el error correspondiente.


Por otro lado se genera el c칩digo de parseo especifico para cada gram치tica. Esto se realiza escribiendolo en el standard output, 
por lo que es necesario ejecutarlo de la siguiente manera: \emph{python programa > "ParserEll1.cpp"} para redirigir la salida al archivo \emph{ParserEll1.cpp}.


El programa lo que hace es primero obtener los diccionarios \emph{siguientes} y \emph{primeros}, y una vez que se obtienen se imprimen una serie de lineas que corresponden a ciertos include genericos de las librerias que usar치. Y luego se imprime para cada nodo No-Terminal una funci칩n, que tiene como nombre \emph{Porc\_<Nombre Nodo>()} y para escribir el cuerpo de la misma se recorre el subgrafo que define el nodo llegando hasta las hojas o los nodos no terminales que se encuentren, para cada hijo se escribe:


\begin{itemize}
\item Si es un Terminal se hace un \emph{match(<NombreNodo>);}
\item Si es un No Terminal se hace un \emph{Porc\_<Nombre Nodo>()}
\item Si es un ``|'' se hace una serie de \emph{if} para cada uno de sus hijos preguntando si el \emph{TC} est치 en los simbolos directrices de ese nodo, y dentro de cada if se coloca el cuerpo de los hijos y se sigue. Y se termina con un \emph{else} para el caso de error en el que se encuentra un caracter inesperado.
\item Si es un ``.'' se escribe directamente el codigo de todos sus hijos en orden.
\item Si es un ``*'' se escribe un \emph{while} preguntando si en \emph{TC} se encuentra en los Primeros de ese nodo.
\item Si es un ``+'' se actua de manera an치loga al ``*'' pero con un \emph{do while} en vez del \emph{while}.
\end{itemize}


De esta menera se escribe todo el codigo correspondiente a esta gram치tica.


Para compilar el c칩digo simplemente se debe compilar \emph{ParserEll1.cpp} con los archivos \emph{Utilitario.cpp} y \emph{codigoParser.cpp} en el mismo directorio.


Para ejecutarlo con la cadena \emph{cadena} se debe ejecutar (en Linux): \emph{nombreDelEjecutable  $<<<$  ``cadena''}.


\end{document}